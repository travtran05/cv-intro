{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Just to push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('rov_pool.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "edges = cv2.Canny(gray, 106, 107, apertureSize=3) # detect edges, gray is image in grayscale, 50 and 150 represent 2 images that have been threshholded at 2 different levels, apertureSize controls how much light the image gets and how exposed it is\n",
    "lines = cv2.HoughLinesP(\n",
    "                edges, #described above\n",
    "                1, #1 pixel resolution parameter\n",
    "                np.pi/180, # 1 degree resolution parameter\n",
    "                60, #min number of intersections/votes\n",
    "                minLineLength=475,\n",
    "                maxLineGap=100,\n",
    "        ) # detect lines\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    slope = (y2-y1)/(x2-x1)\n",
    "    print(str(slope))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLines(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 90, 100, apertureSize=3) \n",
    "    lines = cv2.HoughLinesP(\n",
    "                    edges, #described above\n",
    "                    1, #1 pixel resolution parameter\n",
    "                    np.pi/180, # 1 degree resolution parameter\n",
    "                    10, #min number of intersections/votes\n",
    "                    minLineLength=10,\n",
    "                    maxLineGap=60,\n",
    "            ) # detect lines\n",
    "    try:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            print(str(slope))\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture('AUV_Vid.mkv')\n",
    "\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_file = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter(output_file, fourcc, 30, (width, height))\n",
    "\n",
    "ret, frame = video.read()\n",
    "count = 0\n",
    "frequency = 1\n",
    "\n",
    "while ret:\n",
    "    if count % frequency == 0:\n",
    "        processed_frame = drawLines(frame)\n",
    "        output_video.write(processed_frame)\n",
    "\n",
    "    count += 1\n",
    "    ret, frame = video.read()\n",
    "\n",
    "video.release()\n",
    "output_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('AUV_Vid.mkv')\n",
    "ret, frame = video.read()\n",
    "count = 0\n",
    "frequency = 150\n",
    "while ret:\n",
    "\n",
    "    if count % frequency == 0:\n",
    "        plt.imshow(cv2.cvtColor(drawLines(frame), cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        \n",
    "    count+=1\n",
    "    ret, frame = video.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dt_apriltags import Detector\n",
    "img = cv2.imread('test_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "at_detector = Detector(families='tag36h11', #controls what it is supposed to detect\n",
    "                       nthreads=1, #controls the number of threads used in the detection\n",
    "                       quad_decimate=1.0, #controls to what scale the image is lowered in resolution\n",
    "                       quad_sigma=0.0, #blur applied to the image to reduce noise\n",
    "                       refine_edges=1, #attempts to redefine the edges of the tag boundaries\n",
    "                       decode_sharpening=0.25, #controls how much the image is sharpened after the tags are discovered\n",
    "                       debug=0) # no debugging information will be produced\n",
    "\n",
    "tags = at_detector.detect(img, estimate_tag_pose=False, camera_params=None, tag_size=None)\n",
    "\n",
    "color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "for tag in tags:\n",
    "    for idx in range(len(tag.corners)):\n",
    "        cv2.line(color_img, tuple(tag.corners[idx - 1, :].astype(int)), tuple(tag.corners[idx, :].astype(int)), (0, 255, 0))\n",
    "\n",
    "    cv2.putText(color_img, str(tag.tag_id),\n",
    "                org=(tag.corners[0, 0].astype(int) + 10, tag.corners[0, 1].astype(int) + 10),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=0.8,\n",
    "                color=(0, 0, 255))\n",
    "    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travistran/cv-intro/lane_detection.py:78: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  slope = (y2-y1)/(x2-x1)\n",
      "/home/travistran/cv-intro/lane_detection.py:113: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  xPoint = ((slopeList[i] * xInterceptList[i]) - (slopeList[j] * xInterceptList[j]))/(slopeList[i]-slopeList[j])\n",
      "/home/travistran/cv-intro/lane_detection.py:108: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  interceptDist = abs(xInterceptList[i]-xInterceptList[j])\n",
      "/home/travistran/cv-intro/lane_detection.py:109: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  slopeDiff = abs((1/ slopeList[i]) - (1/slopeList[j]))\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m(i\u001b[39m%\u001b[39m\u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m90\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     lines \u001b[39m=\u001b[39m detect_lines(frame, \u001b[39m50\u001b[39;49m, \u001b[39m90\u001b[39;49m, \u001b[39m3\u001b[39;49m,\u001b[39m150\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m     \u001b[39m#print (lines)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m     \u001b[39m#try: \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39m#except :\u001b[39;00m\n\u001b[1;32m     32\u001b[0m    \u001b[39m#     pass\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/cv-intro/lane_detection.py:30\u001b[0m, in \u001b[0;36mdetect_lines\u001b[0;34m(img, threshold1, threshold2, apertureSize, minLineLength, maxLineGap)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_lines\u001b[39m(img, threshold1 \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m, threshold2 \u001b[39m=\u001b[39m \u001b[39m150\u001b[39m, apertureSize \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, minLineLength \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, maxLineGap \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    takes an image as an input and returns a list of detected lines\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY) \u001b[39m# convert to grayscale\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     edges \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCanny(gray, threshold1, threshold2, apertureSize \u001b[39m=\u001b[39m apertureSize) \u001b[39m# detect edges, gray is image in grayscale, 50 and 150 represent 2 images that have been \u001b[39;00m\n\u001b[1;32m     32\u001b[0m                                                       \u001b[39m# threshholded at 2 different levels, apertureSize controls how much light the image gets and how exposed it is\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dt_apriltags import Detector\n",
    "import matplotlib.cm as cm\n",
    "from lane_detection import *\n",
    "from lane_following import *\n",
    "\n",
    "video = cv2.VideoCapture('AUV_Vid.mkv')\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_file = 'output_video_center.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter(output_file, fourcc, 30, (width, height))\n",
    "\n",
    "i = 0\n",
    "ret = True\n",
    "while ret:\n",
    "    slopeSet = set() \n",
    "    i += 1\n",
    "    ret, frame = video.read()\n",
    "    if(i%1 == 0 and i > 90):\n",
    "        lines = detect_lines(frame, 50, 90, 3,150,10)\n",
    "        #print (lines)\n",
    "    \n",
    "        #try: \n",
    "        #    frame = draw_lines(frame, lines,(0, 255, 0))\n",
    "        #    print (\"tried to draw lines\")\n",
    "        #except :\n",
    "       #     pass\n",
    "        try:\n",
    "            lanes = detect_lanes(lines)\n",
    "            #print (\"tried to detect lanes\")\n",
    "            pickedLane = pick_lane(lanes)\n",
    "            frame = draw_Single_lane(frame, pickedLane, (255, 0, 0))\n",
    "            frame = draw_lines(frame, lines,(0, 255, 0))\n",
    "            center_intercept, center_slope = get_lane_center(pickedLane)\n",
    "            xPoint = pickedLane[0][2]\n",
    "            yPoint = pickedLane[0][3]\n",
    "            cv2.line(frame, (int(center_intercept), 1080), (int(xPoint), int(yPoint)), (0,0,255), 3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "        output_video.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "video.release()\n",
    "output_video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
